{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5417dac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geneformer\n",
    "from geneformer import TranscriptomeTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import loompy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a60c29-4104-4b3e-b393-5088149c85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/u/home/r/ramadas/geneformer_tokenized_data\"\n",
    "output_path = \"/u/home/r/ramadas/geneformer_tokenized_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3b2d2d0-aa89-478b-9814-b2408b56a0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available column attributes (ca): ['cd_status', 'n_counts', 'obs_names', 'stimulation']\n",
      "<loompy.loompy.LoomConnection object at 0x2ac872c81450>\n"
     ]
    }
   ],
   "source": [
    "# A loom file is basically a transpose of a h5ad file (which is what our data is currently stored in)\n",
    "\n",
    "\n",
    "ds = loompy.connect(\"/u/home/r/ramadas/geneformer_tokenized_data/labeled_t_cell_data.loom\") # Open a loom file\n",
    "ds.shape\n",
    "print(\"Available column attributes (ca):\", list(ds.ca.keys()))\n",
    "print(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "229f0c77-5106-41eb-9ccf-af11c0e0ff97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available column attributes (ca): ['cd_status', 'n_counts', 'obs_names', 'stimulation']\n",
      "Available row attributes (ra): ['ensembl_id']\n"
     ]
    }
   ],
   "source": [
    "print(\"Available column attributes (ca):\", list(ds.ca.keys()))\n",
    "print(\"Available row attributes (ra):\", list(ds.ra.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb63688-df7a-41af-ad4b-d33e9142a667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Geneformer created new models so we have to specify \n",
    "tk = TranscriptomeTokenizer({'stimulation': 'stimulation'}, nproc=16, model_input_size = 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c212323-f529-4782-9248-f270d0179198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stimulation values: [np.str_('rest'), np.str_('act'), np.str_('rest'), np.str_('rest'), np.str_('rest')]\n"
     ]
    }
   ],
   "source": [
    "print(\"Stimulation values:\", list(ds.ca['stimulation'])[:5])  # Print first 5 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa7e40d-36ba-459f-a26a-8a74ae93517f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing /u/home/r/ramadas/geneformer_tokenized_data/labeled_t_cell_data.loom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 94/94 [01:18<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/u/home/r/ramadas/geneformer_tokenized_data/labeled_t_cell_data__dedup.loom has no column attribute 'filter_pass'; tokenizing all cells.\n",
      "Creating dataset.\n"
     ]
    }
   ],
   "source": [
    "tk.tokenize_data(data_path, output_path, \"Q_data_\", file_format=\"loom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5eb50d9-947d-44aa-a24a-b9b6b9c07ec8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Directory /u/scratch/r/ramadas/geneformer_tokenized_data/Q_data_.dataset is neither a `Dataset` directory nor a `DatasetDict` directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# code to generate k5 cv datasplit\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_from_disk\n\u001b[0;32m----> 3\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/u/scratch/r/ramadas/geneformer_tokenized_data/Q_data_.dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(ds\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/datasets/load.py:2215\u001b[0m, in \u001b[0;36mload_from_disk\u001b[0;34m(dataset_path, keep_in_memory, storage_options)\u001b[0m\n\u001b[1;32m   2213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict\u001b[38;5;241m.\u001b[39mload_from_disk(dataset_path, keep_in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory, storage_options\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   2216\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDirectory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is neither a `Dataset` directory nor a `DatasetDict` directory.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2217\u001b[0m     )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Directory /u/scratch/r/ramadas/geneformer_tokenized_data/Q_data_.dataset is neither a `Dataset` directory nor a `DatasetDict` directory."
     ]
    }
   ],
   "source": [
    "# code to generate k5 cv datasplit\n",
    "from datasets import load_from_disk\n",
    "ds = load_from_disk(\"/u/home/r/ramadas/geneformer_tokenized_data/Q_data_.dataset\")\n",
    "print(ds.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be2636-72db-4d97-8832-6cefa7ceca74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# in order to run a cross validation of k=5 make ds row be a multiple of 5(bad code in Geneformer split)\n",
    "n = ds.shape[0]\n",
    "rows_drop = n % 5\n",
    "\n",
    "if rows_drop > 0:\n",
    "    ds = ds.select(range(n - rows_drop))\n",
    "    print(ds.shape)\n",
    "\n",
    "ds.save_to_disk(\"/u/home/r/ramadas/geneformer_tokenized_data/Q_data_k5.dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970564e3-0998-420c-99d6-27b97e396aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1_env",
   "language": "python",
   "name": "test1_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
